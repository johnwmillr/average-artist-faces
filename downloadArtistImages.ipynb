{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download artist images\n",
    "\n",
    "We want images of faces for rap, rock, and country artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T05:41:14.992524Z",
     "start_time": "2018-12-20T05:41:12.999745Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import cv2\n",
    "import wikipedia\n",
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T05:41:15.037969Z",
     "start_time": "2018-12-20T05:41:15.016892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the Matplotlib defaults\n",
    "colors = np.array([(182,109,255),(218,109,0),(0,146,146)])/255\n",
    "plt.rcParams.update({'font.size': 16, 'figure.figsize': (12.0, 6.0)})\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect lists of artist names from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get artist names from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Category:American_female_country_singers\",\n",
    "              \"Category:American_male_rappers\",\n",
    "              \"Category:American_female_rappers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category:American_female_country_singers\n",
      "['Connie Francis', 'Paula Frazer', 'Adrianna Freeman', 'Dori Freeman']\n",
      "['Moonshine Kate', 'Abra Moore', 'Allison Moorer', 'Heather Morgan (songwriter)']\n",
      "['Chickie Williams', 'Dar Williams', 'Holly Williams', 'Joy Williams (singer)']\n",
      "['Pia Zadora', 'Andrea Zonn']\n",
      "Reached the last page.\n",
      "\n",
      "Category:American_male_rappers\n",
      "['Meechy Darko', 'Datin (rapper)', 'Deacon the Villain', 'Menace Demarco']\n",
      "['Rob Sonic', 'Souleye (hip hop artist)', 'Bubba Sparxxx', 'Speak!']\n",
      "['Jonny Z', 'VZilla', 'Zombie Juice']\n",
      "Reached the last page.\n",
      "\n",
      "Category:American_female_rappers\n",
      "['Shawnna', 'Magnolia Shorty', 'Shunda K', 'Natalie Sims']\n",
      "['Yo-Yo (rapper)', 'Yoon Mi-rae', 'Young M.A', 'Maimouna Youssef']\n",
      "Reached the last page.\n",
      "Found 1234 total names.\n"
     ]
    }
   ],
   "source": [
    "# Provide the content category and starting URL\n",
    "root = \"https://en.wikipedia.org\"\n",
    "artist_names = {}\n",
    "total = 0\n",
    "for category in categories:\n",
    "    print(\"\\n\" + category)\n",
    "    url = f\"{root}/wiki/{category}\"\n",
    "    key = category.split(\":\")[-1].lower()\n",
    "\n",
    "    # Start searching through pages\n",
    "    reached_last_page = False\n",
    "    while not reached_last_page:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # Find the names on the page\n",
    "        letter_groups = soup.find_all(class_=\"mw-category-group\")[1:]\n",
    "        for group in letter_groups:\n",
    "            names_in_group = list(map(lambda x: x.text, group.find_all(\"li\")))\n",
    "            names_in_group = [name for name in names_in_group if not name.startswith(\"â–º\")]\n",
    "            total += len(names_in_group)\n",
    "            artist_names.setdefault(key, []).extend(names_in_group)\n",
    "        print(names_in_group[-4:])\n",
    "\n",
    "        # Find the link to the next page\n",
    "        prev_next_links = soup.find_all(title=category.replace(\"_\", \" \"))\n",
    "        if prev_next_links and \"next\" in prev_next_links[-1].text:\n",
    "            prev_next_links = prev_next_links[-1]\n",
    "            url = root + prev_next_links.get(\"href\") # URL for the next page\n",
    "        else:\n",
    "            print(\"Reached the last page.\")\n",
    "            reached_last_page = True\n",
    "        time.sleep(0.5)\n",
    "print(f\"Found {total} total names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Female rock singers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 610 total names.\n"
     ]
    }
   ],
   "source": [
    "category = \"List_of_female_rock_singers\"\n",
    "root = \"https://en.wikipedia.org\"\n",
    "url = f\"{root}/wiki/{category}\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "ul = soup.find_all(\"ul\")\n",
    "names = []\n",
    "for section in ul[1:26]:\n",
    "    names.extend(map(lambda x: x.text, section.find_all(\"li\")))\n",
    "print(f\"Found {len(names)} total names.\")\n",
    "artist_names.setdefault(\"female_rock_singers\", []).extend(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male rock singers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 total names.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://digitaldreamdoor.com/pages/best_vocalists.html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "table = soup.find_all(\"table\", class_=\"t7\")[0]\n",
    "columns = table.find_all(\"td\", class_=\"td16a\")\n",
    "names = []\n",
    "for column in columns:\n",
    "    names.extend(list(map(lambda x: x.split(\".\")[-1].strip(), column.text.strip().split(\"\\n\"))))\n",
    "print(f\"Found {len(names)} total names.\")\n",
    "artist_names.setdefault(\"male_rock_singers\", []).extend(names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male country singers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 904 total names.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.countrystartpage.com/music-directory/male/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "div = soup.find(class_=\"uk-margin-remove-top uk-grid-margin uk-margin-remove-top\")\n",
    "names = [item.text.split(\"/\")[0].strip() for item in div.find_all(\"li\")]\n",
    "print(f\"Found {len(names)} total names.\")\n",
    "artist_names.setdefault(\"male_country_singers\", []).extend(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the different name sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected a total of 2948 artist names.\n"
     ]
    }
   ],
   "source": [
    "all_artist_names = {}\n",
    "all_artist_names[\"RAP_FEMALE\"] = artist_names[\"american_female_rappers\"]\n",
    "all_artist_names[\"RAP_MALE\"] = artist_names[\"american_male_rappers\"]\n",
    "all_artist_names[\"ROCK_FEMALE\"] = artist_names[\"female_rock_singers\"]\n",
    "all_artist_names[\"ROCK_MALE\"] = artist_names[\"male_rock_singers\"]\n",
    "all_artist_names[\"COUNTRY_FEMALE\"] = artist_names[\"american_female_country_singers\"]\n",
    "all_artist_names[\"COUNTRY_MALE\"] = artist_names[\"male_country_singers\"]\n",
    "print(f\"Collected a total of {sum(map(len, all_artist_names.values()))} artist names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the artist names dictionary to a pickle.\n"
     ]
    }
   ],
   "source": [
    "with open(\"artist_names.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(all_artist_names, outfile)\n",
    "print(\"Saved the artist names dictionary to a pickle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download images while checking for faces\n",
    "\n",
    "## google_images_download\n",
    "\n",
    "https://google-images-download.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_images_download.googleimagesdownload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for finding faces in the image\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCK_MALE\n",
      "(1/200) || Time elapsed: 0.00 minutes.\n",
      "Downloading images for: Freddie Mercury (Queen Solo) ROCK ...\n",
      "https://www.billboard.com/files/styles/article_main_image/public/media/freddie-mercury-queen-1982-r-billboard-1548.jpg\n",
      "ERROR\n",
      "HTTP Error 403: Forbidden\n",
      "Total time elapsed: 0.05 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Get the image URLs for the artist\n",
    "t0 = time.time()\n",
    "output_dir = \"./face_image_downloads_v2/\"\n",
    "# for genre_gender, artist_names in all_artist_names.items():\n",
    "d = {key:all_artist_names[key] for key in [\"ROCK_MALE\", \"COUNTRY_MALE\", \"COUNTRY_FEMALE\"]}\n",
    "for genre_gender, artist_names in d.items():\n",
    "    print(genre_gender)\n",
    "    genre, gender = genre_gender.split(\"_\")\n",
    "    for n, name in enumerate(artist_names):\n",
    "        name = name.replace(\",\", \"\")\n",
    "        try:\n",
    "            query = name + \" \" + genre\n",
    "            if n % 50 == 0:\n",
    "                print(f\"({n+1}/{len(artist_names)}) || Time elapsed: {(time.time() - t0) / 60:.2f} minutes.\")\n",
    "\n",
    "            # Google Image Search\n",
    "            prefix = genre_gender\n",
    "            args = {\"keywords\": query, \"limit\": 3, \"prefix\": prefix, \"silent_mode\": True,\n",
    "                    \"output_directory\": output_dir, \"no_directory\": True, \"delay\": 0.1,\n",
    "                    \"save_source\": \"face_image_urls\", \"print_urls\": False,\n",
    "                    \"no_download\": True, \"size\": \"medium\", \"color_type\": \"full-color\"}\n",
    "            image_path = response.download(args)\n",
    "            prefix = output_dir + prefix\n",
    "\n",
    "            # Check the image URLs for a fOace\n",
    "            for url in image_path[0][query]:\n",
    "                print(url)\n",
    "                try:\n",
    "                    # Read the image URL\n",
    "                    image = io.imread(url)[...,::-1]\n",
    "                   \n",
    "                    # Try to detect a face in the image\n",
    "                    found_array = detector(image, 1)\n",
    "                    if len(face_array) == 1: # Only download images with a single face\n",
    "                        # Format the filename\n",
    "                        ext = url.rsplit(\".\")[-1]\n",
    "                        fp = output_dir + genre + \"_\" + gender + \"_\" + name + \".\" + ext\n",
    "                        fp = fp.split(\"?\", 1)[0]\n",
    "\n",
    "                        # Save the image\n",
    "                        print(\"hi\")\n",
    "                        cv2.imwrite(fp, image)\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR\")\n",
    "                    print(e)\n",
    "                    break\n",
    "            time.sleep(2.5) # Wait a little bit\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'big wait: {e}')\n",
    "            time.sleep(1)\n",
    "            break\n",
    "    break\n",
    "print(f\"Total time elapsed: {(time.time() - t0) / 60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the downloaded file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in [\"?\", \"%\"]:\n",
    "    image_paths = glob(\"./face_image_downloads/*\")\n",
    "    new_names = list(map(lambda x: x.split(char)[0], image_paths))\n",
    "    for old, fp in zip(image_paths, new_names):\n",
    "        os.rename(old, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
